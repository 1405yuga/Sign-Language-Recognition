# Sign-Language-Recognition
Sign Language Recognition is the project where a sign detector is created, which detects numbers from 0 â€“ 9 of hand gestures.In this project, American Sign Language is used. This can be very helpful for the deaf and dumb people in communicating with others as knowing sign language is not something that is common to all, moreover, this can be extended to creating automatic editors, where the person can easily write by just their hand gestures. Here recognition is done on the basis of supervised machine learning model.

### Hand gestures according to American Sign Language is displayed as :

<img src="https://github.com/1405yuga/Sign-Language-Recognition/assets/82303711/26261fb6-4866-4252-8e82-2993fade7ccf">


## Guide

### Home:

This is the fisrt and common user interface page for all the features that are there in this project.

<img src="https://github.com/1405yuga/Sign-Language-Recognition/assets/82303711/74154e58-0e1a-4fb2-851d-514571006861"  width="700" height="400">


<br/>

### Aim:

This is one of the feature which displays the aim and objectives of this application.

<img src="https://github.com/1405yuga/Sign-Language-Recognition/assets/82303711/d2e38a54-7dcb-4489-a175-8722508f4360"  width="700" height="400">

<br/>

### Start Camera:

Live video streaming is started. The user has to show the gesture that has to be predicted in the yellow box designed in it. The predicated value is later displayed in the box in real time.

<img src="https://github.com/1405yuga/Sign-Language-Recognition/assets/82303711/0a64144c-b481-483b-9199-68687ee72ef9"  width="700" height="400">

<br/>

### Help:

This feature displays the step-wise instructions of how to use this application.

<img src="https://github.com/1405yuga/Sign-Language-Recognition/assets/82303711/30a9651d-785c-4d31-a8b1-94dd78c9226d"  width="700" height="400">

